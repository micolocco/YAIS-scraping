{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# YAIS: Yet Another Introduction to Scraping\n",
    "\n",
    "###### Let's talk about scraping today!\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "MLJC @ Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Today's Big Mission\n",
    "\n",
    "* Understand the concepts underlying scraping to start being confident and scrape by yourself\n",
    "* Know about common pittfalls and scraping related problems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To follow step by step: \n",
    "\n",
    "* create a virtual environment: `conda create -n scraping` or something else\n",
    "* activate the virtual env: `conda activate scraping`\n",
    "* install the deps: `pip install -r requirements.txt`\n",
    "* run the notebook: `jupyter notebook scraping.ipynb` or something else\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Just stop me and ask whenever you want!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What is scraping?\n",
    "\n",
    "Scraping is just a fancy word that stands for a **data collection** activity. To be more precise, scraping is a (not so new, did you ever heard *screen reading*?) way to perform data collection from webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Why scraping?\n",
    "\n",
    "\"*Data is the new oil*\" bla bla bla... To verify our hypthesis, get insights and to understand the world quantitatively, we just need data!\n",
    "\n",
    "Web is full of data but in a **unstructured** format, so scraping is just **searching + structuring information** in a way that is useful for our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### When we should scrape the web?\n",
    "\n",
    "When an official API is not available!\n",
    "APIs are \"services\" that websites offers to give access to their data in a programmatic way. \n",
    "\n",
    "When a website release an API they are just implicitely telling us what data and how this data should be accessed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's make a quick example with a [free access API](https://datausa.io/about/api/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# make a request to datausa.io API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import requests\n",
      "import pprint\n",
      "\n",
      "url = \"https://datausa.io/api/data\"\n",
      "params = {\"drilldowns\":\"Nation\",\n",
      "          \"measures\": \"Population\",\n",
      "          \"year\": \"latest\"}\n",
      "\n",
      "resp = requests.get(url,params)\n",
      "resp.json()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trick for reveal js speaker notes\n",
    "print(\"\"\"import requests\n",
    "import pprint\n",
    "\n",
    "url = \"https://datausa.io/api/data\"\n",
    "params = {\"drilldowns\":\"Nation\",\n",
    "          \"measures\": \"Population\",\n",
    "          \"year\": \"latest\"}\n",
    "\n",
    "resp = requests.get(url,params)\n",
    "resp.json()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Do we really need of scraping at all?\n",
    "* Websites saldomly provides APIs.\n",
    "* Usually an API requires a **paid subscription** or some form of **restricted access** (eg. [IMDB data](https://developer.imdb.com/)).\n",
    "* Usually APIs have some kind of **requests limits** to preserve server resources.\n",
    "* API doesn't provide the wanted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To get a solid understanding we need to get a glimpse of the fundamental blocks on which scraping libraries build upon, that is the *Fab Four* of the web tech stack.\n",
    "\n",
    "<img src=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/http-layers.png\" width=40% align=center/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HTTP\n",
    "\n",
    "A standardized protocol based on **client-server** model, which specify the structure of the messages sent between clients and servers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the stone-age ...\n",
    "\n",
    "1. Client (aka *user-agent*) **send a request** to fetch the HTML page or a resource $\\rightarrow$ *whom to contact*? \n",
    "2. Server (should) send back a **reply** with the given resource $\\rightarrow$ *what could go [wrong](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#5xx_server_errors)*?\n",
    "3. Client **parse** the response, if it's a [successful one](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#2xx_success), **render** the content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "... Nowadays\n",
    "<center> <img src=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/fetching_a_page.png\" width=65% /> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### With a little help from my friends\n",
    "\n",
    "Let's [explore](https://developer.mozilla.org/en-US/) *developer tools' network* tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll use [Requests](https://docs.python-requests.org/en/master/user/quickstart/) library in order to send and receive HTTP messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# make an HTTP GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import requests\n",
      "\n",
      "url = \"https://developer.mozilla.org/\"\n",
      "url_params = {\"test_param\":23}\n",
      "resp = requests.get(url, params=url_params)\n",
      "\n",
      "resp.status_code\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "import requests\n",
    "\n",
    "url = \"https://developer.mozilla.org/\"\n",
    "url_params = {\"test_param\":23}\n",
    "resp = requests.get(url, params=url_params)\n",
    "\n",
    "resp.status_code\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## HTML\n",
    "\n",
    "HTML main purpose is to define the **structure** of a web page.\n",
    "\n",
    "HTML files contains a series of **nested elements** that wrap the content and make it appear or beahave in a certain way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics/grumpy-cat-small.png\" width=70% /></center>\n",
    "\n",
    "HTML elements could also have attached *attributes*\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics/grumpy-cat-attribute-small.png\" width=75% /></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### HTML DOM\n",
    "\n",
    "\n",
    "\n",
    "```HTML\n",
    "<body>\n",
    "    <h1> Title </h1>\n",
    "    <p> Lorem ipsum dolor sit amet </p>\n",
    "    <ul>\n",
    "        <li> ... </li>\n",
    "        <li> ... </li>\n",
    "        <li> ... </li>\n",
    "    </ul>\n",
    "</body>\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"https://www.dottedsquirrel.com/content/images/2021/03/csssiblings.png\" width=70% />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can parse and access HTML elements using [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# parse the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "html_doc = resp.content\n",
      "soup = BeautifulSoup(html_doc, 'html.parser')\n",
      "\n",
      "print(soup.prettify()[:200])\n",
      "\n",
      "print(soup.head.prettify())\n",
      "print(type(soup.head))\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = resp.content\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "print(soup.prettify()[:200])\n",
    "\n",
    "print(soup.head.prettify())\n",
    "print(type(soup.head))\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### With a little help from my friends\n",
    "\n",
    "Let's explore *developer tools' elements* tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try to extract blog post titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# extract blog articles titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for el in soup.find_all(\"h3\"):\n",
      "    print(el.a.text)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "for el in soup.find_all(\"h3\"):\n",
    "    print(el.a.text)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSS\n",
    "\n",
    "The main purpose of CSS is to define the HTML elements **style** (eg. sizes, colors, animations, etc...). \n",
    "\n",
    "Beforehand to specify the style of an element we need to **select** it, right? These is what **CSS selectors** are used for! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "CSS selectors is a *mini-language* that allows you to select one or multiple elements in a very clever way.\n",
    "```\n",
    ".classes\n",
    "#ids\n",
    "[attributes=value]\n",
    "parent child\n",
    "parent > child\n",
    "sibling ~ sibling\n",
    "sibling + sibling\n",
    ":not(element.class, element2.class)\n",
    ":is(element.class, element2.class)\n",
    "parent:has(> child)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# build a mini dataset from Mozilla's blog articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "post_elements = soup.select(\"div.blog-feed > ul > li\")\n",
      "\n",
      "titles = []\n",
      "urls = []\n",
      "descriptions = []\n",
      "dates = []\n",
      "authors = []\n",
      "\n",
      "for post_el in post_elements:\n",
      "    titles.append(post_el.h3.text) \n",
      "    \n",
      "    urls.append(post_el.h3.a[\"href\"])\n",
      "    \n",
      "    post_meta = post_el.select_one(\"p.post-meta\").text\n",
      "    date, author = post_meta.replace(\"Posted\",\"\").strip().split(\" by \") \n",
      "    dates.append(date)\n",
      "    authors.append(author)\n",
      "    \n",
      "    descriptions.append(post_el.select_one(\"p:not(.post-meta)\").text) \n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "mini_dataset = pd.DataFrame({\"title\": titles, \"url\":urls,\n",
      "                             \"description\": descriptions, \"dates\": dates,\n",
      "                             \"author\": authors})\n",
      "\n",
      "mini_dataset.to_csv(\"mini_dataset_mozilla.csv\")\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "post_elements = soup.select(\"div.blog-feed > ul > li\")\n",
    "\n",
    "titles = []\n",
    "urls = []\n",
    "descriptions = []\n",
    "dates = []\n",
    "authors = []\n",
    "\n",
    "for post_el in post_elements:\n",
    "    titles.append(post_el.h3.text) \n",
    "    \n",
    "    urls.append(post_el.h3.a[\"href\"])\n",
    "    \n",
    "    post_meta = post_el.select_one(\"p.post-meta\").text\n",
    "    date, author = post_meta.replace(\"Posted\",\"\").strip().split(\" by \") \n",
    "    dates.append(date)\n",
    "    authors.append(author)\n",
    "    \n",
    "    descriptions.append(post_el.select_one(\"p:not(.post-meta)\").text) \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "mini_dataset = pd.DataFrame({\"title\": titles, \"url\":urls,\n",
    "                             \"description\": descriptions, \"dates\": dates,\n",
    "                             \"author\": authors})\n",
    "\n",
    "mini_dataset.to_csv(\"mini_dataset_mozilla.csv\")\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some stuff to notice:\n",
    "* the selected element is always the **right-most**.\n",
    "* the selection is always **relative** to the (root) node we are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## All you need is XPath\n",
    "\n",
    "Query language for selecting HTML (XML) elements.\n",
    "\n",
    "<img src=\"https://www.softwaretestinghelp.com/wp-content/qa/uploads/2019/05/XPATH-Syntax-screenshot-1-1.png\" width=60% />\n",
    "\n",
    "Some advantages:\n",
    "* Bidirectional flow $\\rightarrow$ moving left-right, up-down\n",
    "* Partial matching with *contains()*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# JS\n",
    "\n",
    "JS main purpose is to add **dynamic functionalities and behaviours** to a web page.\n",
    "\n",
    "JS code **could change** the underlying HTML structure or elements styles, but can also \"silently\" send HTTP requests to other servers (eg. for retrieving data from web api)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### With a little help from my friends\n",
    "\n",
    "Let's explore *view source* of [this website](http://elezioni2015.consiglioveneto.it/elezioni2015/regionali/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Headless browsers to the rescue\n",
    "\n",
    "Provides automated control of a web page without actually render and display it:\n",
    "* js running\n",
    "* automatic interaction (eg. click on an button, compiling a form, etc.)\n",
    "\n",
    "Some solutions:\n",
    "* [requests-html](https://github.com/psf/requests-html)\n",
    "* [Selenium](https://selenium.dev)\n",
    "* [Scrapy-selenium](https://github.com/clemfromspace/scrapy-selenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping or Crawling?\n",
    "\n",
    "* extract information from few web pages $\\rightarrow$ scraping üîé\n",
    "* discover rules and links following? $\\rightarrow$ \"Crawl it up baby now\" üíÉüï∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " #### Scrapy\n",
    "    \n",
    "Scrapy is a *framework*, so it expects from you to:\n",
    "\n",
    "* fit your mental model to the framework conceptual model and execution flow\n",
    "* follow conventions and rules (eg. directories stucture)\n",
    "* extend and use framework' classes and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How Scrapy works?\n",
    "\n",
    "<img src=\"https://docs.scrapy.org/en/latest/_images/scrapy_architecture_02.png\" width=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's crawl [Pagella Politica](https://pagellapolitica.it/) to build a fact checking dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Scrapy CLI\n",
    "\n",
    "Scray provides a CLI tool to manage projects and spiders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To initialize a project:\n",
    "\n",
    "```scrapy startproject fact_checking```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To create a spider:\n",
    "\n",
    "`scrapy genspider pagellapolitica pagellapolitica.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To run the spider:\n",
    "\n",
    "`scrapy crawl pagellapolitica`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's switch to the same ol' vs code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Legal and Ethical Concerns\n",
    "\n",
    "Is web scraping a legal activity? \n",
    "\n",
    "... \"ish\"\n",
    "\n",
    "We are collecting public available data after all... but be a nice human:\n",
    "* present yourself: leave information about the crawlers owners and how to contact you \n",
    "* respect *robots.txt*\n",
    "* limits your requests firing rate\n",
    "* check the  website' *terms and conditions*.\n",
    "* respect the website owner's will. [Read more](https://jaxenter.com/data-scraping-cases-165385.html) \n",
    "\n",
    "Remember: scraping always implies consuming someone else computing resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some tips:\n",
    "\n",
    "* Check the API then scrape by yourself\n",
    "* Select your elements with \"*least-likely change*\" heuristic\n",
    "* Nowadays web is dynamic! Always check page source code.\n",
    "* Web page evolves, your scraper should change accordingly. Try to anticipate these changes and make a robust scraper!\n",
    "* Scraping some pages could be not so easy: frontend developers will be your best friends üë©‚Äçüíªüë®‚Äçüíª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Did you find the easter-eggs?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://londonita.com/wp-content/uploads/2020/02/Abbey-Road-beatles.jpg\" width=45% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "References\n",
    "\n",
    "* for HTTP, HTML, CSS, JS: [MDN web docs](https://developer.mozilla.org/en-US/docs/Web)\n",
    "* for CSS selectors: [dotted squirrel visual guide](https://www.dottedsquirrel.com/the-ultimate-visual-guide-to-css-selectors/)\n",
    "* Scrapy: [official documentation](https://docs.scrapy.org/en/latest/)\n",
    "\n",
    "Further readings: Seppe Vanden, BrouckeBart Baesens; [Practical Web Scraping for Data Science](https://link.springer.com/book/10.1007/978-1-4842-3582-9)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "d6276d485b35ba42ea6e9b54e122e31e4d2de6f28e316ab2edf21d84add80407"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
